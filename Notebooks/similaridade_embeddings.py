# -*- coding: utf-8 -*-
"""Similaridade_embeddings.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F_95gIogXxYogmN9bkRP6EQz5DWZ0JG1

```
Augusto Sousa Nunes - NºUSP: 11319677
Lua Nardi Quito - NºUSP: 11371270
Lucas Schimidt Coelho - NºUSP: 11913019
Lucas Garzeri de Melo - NºUSP: 13731344
Lucca Baptista Silva Ferraz - NºUSP: 13688134
```

#Imports e dados
"""

# Dependencias base
import pandas as pd
import  matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import re
import statsmodels.api as sm

# Análise linguística
!python -m spacy download pt_core_news_sm
import spacy
nlp = spacy.load("pt_core_news_sm")
!pip install pyphen
import pyphen

# Embeddings - o gensim só é compatível com versões antigas do numpy, utiliza-lo apenas quando for mexer com os embeddings word2vec
'''!pip install numpy==1.24.3
import numpy as np
!pip install -q --upgrade gensim
from gensim.models import KeyedVectors'''
# Bertimbau
import numpy as np
from sentence_transformers import SentenceTransformer

# UMAP para visualização - só funciona com versões atualizadas do numpy, usar apenas quando não for mexer nos embeddings do gensim
!pip install umap-learn
import umap

# Métricas
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import Lasso
from sklearn.model_selection import GridSearchCV

nlp = spacy.load("pt_core_news_sm")
dic = pyphen.Pyphen(lang='pt_BR')

# Drive
from google.colab import drive
drive.mount('/content/drive', force_remount = True)

# Warnings
import warnings
warnings.filterwarnings('ignore')


# Wordcloud
from wordcloud import WordCloud

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import string

import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('punkt_tab')

"""---

## **Base de dados estruturada**
"""

#@title Extração de dados

df = pd.read_csv('/content/drive/MyDrive/Dados ENEM Mineração/Base - Lucca/csv_final.csv')
df.head()

df.info()

"""---"""

#@title Extração de dados

df = pd.read_csv('/content/drive/MyDrive/Dados ENEM Mineração/Base - Lucca/csv_final.csv')
df.head()

df.info()

"""# **Similaridade entre os embeddings das alternativas**




"""

#@title Similaridade entre os embeddings

bert_model = SentenceTransformer("neuralmind/bert-base-portuguese-cased")

def get_bert_embedding(text, model):
    return model.encode(text)

def average_alternatives_similarity(row, alternatives_columns):
    embeddings = []
    for col in alternatives_columns:
        alt_text = row[col]
        if isinstance(alt_text, str) and alt_text.strip():
            emb = get_bert_embedding(alt_text, bert_model)
            embeddings.append(emb)
    if len(embeddings) < 2:
        return np.nan
    embeddings = np.vstack(embeddings)
    sim_matrix = cosine_similarity(embeddings)
    n = embeddings.shape[0]
    avg_sim = (np.sum(sim_matrix) - n) / (n * (n - 1))
    return avg_sim

df_similaridades = bert_embeddings[(bert_embeddings["NU_PARAM_B"] >= -3) & (bert_embeddings["NU_PARAM_B"] <= 3)].copy()
alternatives_columns = ['A', 'B', 'C', 'D', 'E']
df_similaridades["avg_alt_similarity"] = df_similaridades.apply(lambda row: average_alternatives_similarity(row, alternatives_columns), axis=1)
df_similaridades.head()

#@title Correlação: média das similariades x Parâmetro B

df_similaridades[['avg_alt_similarity', 'NU_PARAM_B']].corr()

#@title Scatterplot: média das similariades x Parâmetro B


fig = go.Figure()

fig.add_trace(go.Scatter(
    x=df_similaridades['NU_PARAM_B'],
    y=df_similaridades['avg_alt_similarity'],
    mode='markers',
    marker=dict(
        size=7,
    ),
    hoverinfo='text',
))

fig.update_layout(
    title="Distribuição: média das similariades x Parâmetro B",
    xaxis_title="Parâmetro de dificuldade do item",
    yaxis_title="Média da similaridade entre alternativas",
    template="plotly_white"
)

fig.show()

"""***"""

#@title Similaridade entre o gabarito e o enunciado

def similarity_gabarito_enunciado(row, model):
    correct_letter = row["TX_GABARITO"].strip().lower()
    if correct_letter.upper() in ['A', 'B', 'C', 'D', 'E']:
        alternative_text = row[correct_letter.upper()]
        if isinstance(alternative_text, float):
              alternative_text = str(alternative_text)
    else:
        return np.nan

    embedding_enunciado = get_bert_embedding(row["enunciado"], model)
    embedding_alternative = get_bert_embedding(alternative_text, model)

    norm_enunciado = np.linalg.norm(embedding_enunciado)
    norm_alternative = np.linalg.norm(embedding_alternative)
    if norm_enunciado == 0 or norm_alternative == 0:
        return np.nan

    cosine_sim = np.dot(embedding_enunciado, embedding_alternative) / (norm_enunciado * norm_alternative)
    return cosine_sim

df_similaridades["gabarito_similarity"] = df_similaridades.apply(lambda row: similarity_gabarito_enunciado(row, bert_model), axis=1)
df_similaridades[["TX_GABARITO", "enunciado", "gabarito_similarity"]].head()

#@title Correlação: similariade enunciado-gabarito x Parâmetro B

df_similaridades[['gabarito_similarity', 'NU_PARAM_B']].corr()

#@title Scatterplot: média das similariades x Parâmetro B


fig = go.Figure()

fig.add_trace(go.Scatter(
    x=df_similaridades['NU_PARAM_B'],
    y=df_similaridades['gabarito_similarity'],
    mode='markers',
    marker=dict(
        size=7,
    ),
    hoverinfo='text',
))

fig.update_layout(
    title="Distribuição: média das similariades x Parâmetro B",
    xaxis_title="Parâmetro de dificuldade do item",
    yaxis_title="Média da similaridade entre alternativas",
    template="plotly_white"
)

fig.show()

"""---"""

#@title Similaridade entre as respostas erradas e o enunciado

def average_wrong_similarity(row, alternatives_columns):
    correct_letter = row["TX_GABARITO"].strip().lower()
    if correct_letter.upper() not in alternatives_columns:
        return np.nan
    correct_text = row[correct_letter.upper()]
    emb_correct = get_bert_embedding(correct_text, bert_model)
    similarities = []
    for col in alternatives_columns:
        if col.lower() != correct_letter:
            alt_text = row[col]
            if isinstance(alt_text, str) and alt_text.strip():
                emb_alt = get_bert_embedding(alt_text, bert_model)
                norm_correct = np.linalg.norm(emb_correct)
                norm_alt = np.linalg.norm(emb_alt)
                if norm_correct > 0 and norm_alt > 0:
                    sim = np.dot(emb_correct, emb_alt) / (norm_correct * norm_alt)
                    similarities.append(sim)
    return np.mean(similarities) if similarities else np.nan


df_similaridades["avg_wrong_similarity"] = df_similaridades.apply(lambda row: average_wrong_similarity(row, alternatives_columns), axis=1)
df_similaridades[["TX_GABARITO", "avg_wrong_similarity"]].head()

#@title Correlação similaridade enunciado/respostas erradas x Parâmetro B

df_similaridades[['avg_wrong_similarity', 'NU_PARAM_B']].corr()

#@title Scatterplot: média das similariades das respostas erradas x Parâmetro B


fig = go.Figure()

fig.add_trace(go.Scatter(
    x=df_similaridades['NU_PARAM_B'],
    y=df_similaridades['avg_wrong_similarity'],
    mode='markers',
    marker=dict(
        size=7,
    ),
    hoverinfo='text',
))

fig.update_layout(
    title="Distribuição: média das similariades enunciado/respostas erradas x Parâmetro B",
    xaxis_title="Parâmetro de dificuldade do item",
    yaxis_title="Média da similaridade das respostas erradas com o enunciado",
    template="plotly_white"
)

fig.show()

"""---"""

#@title Diferença entre as similaridades enunciado/gabarito e enunciado/respostas erradas

df_similaridades["diff_similarity"] = df_similaridades["gabarito_similarity"] - df_similaridades["avg_wrong_similarity"]

sns.set_style("darkgrid")

sns.histplot(df_similaridades['diff_similarity'], bins = 20)

#@title Scatterplot

fig = go.Figure()

fig.add_trace(go.Scatter(
    x=df_similaridades['NU_PARAM_B'],
    y=df_similaridades['diff_similarity'],
    mode='markers',
    marker=dict(
        size=7
    ),
    hoverinfo='text'
))

fig.update_layout(
    title="Distribuição: diferença entre as médias de similaridade x Parâmetro B",
    xaxis_title="Parâmetro de dificuldade do item",
    yaxis_title="Diferença entre as similaridades (resposta errada/certa) x enunciado",
    template="plotly_white"
)

fig.show()